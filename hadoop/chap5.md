## 하둡 I/O
하둡은 데이터 I/O를 위한 내장 기본 기능을 제공한다.

### 데이터 무결성 
디스크나 네트워크상의 모든 I/O는 읽기 쓰기이세 에러가 아예 없을 순 없다.  
하둡이 처리하는 데이터의 규모가 클 수록, 데이터가 손상될 가능성도 커진다.  

손상된 데이터를 검출하는 일반적인 방법은 데이터가 시스템에 처음 유입되었을 때와 신뢰할수 없는 통신 채널로 데이터가 전송되었을 때 **체크섬**을 계산하는 것이 있다.  
새롭게 생성된 체크섬이 원본과 일치하지 않는다면 데이터는 손상된 것으로 간주한다.  
주의할 점은 데이터가 아니라 체크섬이 손상될 수도 있는데, 체크섬은 데이터에 비해 매우 작기 때문에 손상 가능성은 매우 낮다.  

#### HDFS 의 데이터 무결성 
HDFS는 모든 데이터를 쓰는 과정에서 체크섬을 계산하고, 읽는 과정에서 검증한다.  
데이터노드는 데이터와 체크섬을 저장하기 전에 수신한 데이터를 검증할 책임이 있다.  
이 같은 검증은 클라이언트로부터 수신한 데이터 또는 복제 과정에서 다른 데이터노드로부터 수신한 데이터에 대해 수행된다.  

클라이언트가 데이터노드로부터 데이터를 읽을 때 클라이언트 역시 데이터노드에 저장된 체크섬과 수신된 데이터로부터 계산된 체크섬을 검증한다.  
각 데이터노드는 체크섬 검증 로그를 영구 저장하기 때문에 각각의 블록이 검증되었던 마지막 시간을 알고 있다.  
클라이언트가 성공적으로 하나의 블록을 검증하고 데이터노드에 알리면 데이터노드는 체크섬 검증에 대한 로그를 갱신한다.  

각 데이터노드는 저장된 모든 블록을 주기적으로 검증하는 DataBlockScanner 를 백그라운드 스레드로 수행한다.  
물리먹 저장 매체에서 발생할 수도 있는 '비트 로트(bit rot)'에 의한 데이터 손실을 피하기 위한 방법이다.  

HDFS는 블록의 복제본을 저장하기 때문에 손상되지 않은 새로운 복제본 생성을 위해 정상 복제본 중 하나를 복사하는 방식으로 손상된 블록을 치료할 수 있다.  
만약 클라이언트가 블록을 읽는 과정에서 에러를 검출하는 훼손된 블록과 데이터노드에 대한 정보를 네임노드에 보고하고 에러를 발생시킨다.  
네임노드는 그 블록 복제본이 손상되었다고 표시하여 다른데서 사용하지 못하게 하고, 해당 블록을 복구한다. 
 
#### LocalFileSystem
하둡 LocalFileSystem 은 클라이언트 측 체크섬을 수행한다.  
filename 이라는 파일을 쓸 때 파일 시스템 클라이언트는 파일과 같은 위치의 디렉터리에 그 파일의 청크별 체크섬이 담긴 .filename.crc라는 숨겨진 파일을 생성한다.  

체크섬은 일반적으로 파일을 읽고 쓰는 시간에 몇 퍼센트의 오버헤드를 추가하는 정도이므로 전체 계산 성능에 미치는 영향이 미미하다.  
만일 기존 파일시스템이 체크섬 기능을 지원한다면, LocalFileSystem 의 체크섬 기능을 비활성화 할 수 있다. 


### 압축 
파일 압축은 파일 저장 공간을 줄이고, 네트워크 또는 디스크로부터 데이터 전송을 고속화할 수 있는 이점이 있다.  
이 이점은 대용량 데이터를 처리할 때 매우 중요하기 때문에 하둡에서 압축이 사용되는 방법을 주의 깊게 살펴봐야 한다.  

다음은 하둡에서 사용할 수 있는 일반적인 알고리즘이다. 

|압축포맷|도구|알고리즘|파일 확장명|분할 가능|
|---|---|---|---|---|
|DEFLATE|N/A|DEFLATE|.deflate|No|
|gzip|gzip|DEFLATE|.gz|No|
|bzip2|bzip2|bzip2|.bz2|Yes|
|LZO|lzop|LZO|.lzo|No|
|LZ4|N/A|LZ4|.lz4|No|
|Snappy|N/A|Snappy|.snappy|No|

모든 압축 알고리즘은 압축과 해제가 빨라질수록 공간이 늘어나는 희생을 감수해야 하기 때문에 공간과 시간은 트레이드오프 관계에 있다.  

#### 압축과 입력 스플릿
압축 포맷이 분할을 지원하는지 여부를 알고 있는 것은 중요하다.  

HDFS에 1GB 크기로 저장된 비압축 파일이 있다.  
128MB 크기의 HDFS 블록 8개가 저장되어 있을 때, 이 파일을 입력으로 사용하는 맵리듀스 잡은 각 맵 태스크에서 독립적으로 처리되는 8개의 스플릿을 만들 것이다.  

만약 어떤 파일이 압축된 크기가 1GB인 gzip 이라고 생각해보자.  
HDFS는 이 파일을 8개의 블록으로 저장 하지만. gzip 은 분할이 불가능 하므로 각 맵 태스크는 각 블록별로 스플릿을 생성하는 것이 불가능하다.  
맵리듀스는 gzip 이 분할 불가능 하단 것을 알기 때문에 파일을 분할하지 않는다. 이것은 제대로 동작은 하지만 데이터 지역성 비용이 발생한다.  
단일 맵 태스크가 8개의 HDFS 블록을 처리해야 하는데, 블록 대부분은 맵 태스크의 로컬에 있지 않을 것이다.  

### 직렬화 
**직렬화**는 네트워크 전송을 위해 구조화된 객체를 바이트 스트림으로 전환하는 과정이다.  
**역직렬화**는 바이트 스트림을 일련의 구조화된 객체로 역전환하는 과정이다.  
직렬화는 프로세스간 통신, 영속저장소와 같은 영역에서 나타난다.  

하둡 시스템은 노드 사이의 프로세스 간 통신을 원격 프로시저 호출을 사용해 구현했다.  
RPC는 메시지를 바이너리 스트림으로 구성하기 위해 직렬화를 사용하고, 원격 노드에서 바이너리 스트림을 원본 메시지로 재구성하기 위해 역직렬화를 사용한다.  
RPC 직렬화 포맷이 유익한 이유는 다음과 같다.

- 간결성  
	간결한 포맷을 사용하면 네트워크 대역폭을 절약할 수 있다.
- 고속화   
	프로세스간 통신은 분산 시스템 백본을 형성하기 때문에 직렬화/역직렬화는 오버헤드가 작아야 한다.
- 확장성  
	새로운 요구사항으로 인해 점차 변경되어야 하므로 확장성이 있어야 한다.
- 상호운용성  
	다양한 언어로 작성된 클라이언트를 지원해야 한다.
	
하둡은 Writeable 이라는 매우 간결하고 빠른 자체 직렬화 포맷을 사용한다. 하지만 확장하거나 자바 외 다른 언어의 사용은 어렵다.  

