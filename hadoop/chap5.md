## 하둡 I/O
하둡은 데이터 I/O를 위한 내장 기본 기능을 제공한다.

### 데이터 무결성 
디스크나 네트워크상의 모든 I/O는 읽기 쓰기이세 에러가 아예 없을 순 없다.  
하둡이 처리하는 데이터의 규모가 클 수록, 데이터가 손상될 가능성도 커진다.  

손상된 데이터를 검출하는 일반적인 방법은 데이터가 시스템에 처음 유입되었을 때와 신뢰할수 없는 통신 채널로 데이터가 전송되었을 때 **체크섬**을 계산하는 것이 있다.  
새롭게 생성된 체크섬이 원본과 일치하지 않는다면 데이터는 손상된 것으로 간주한다.  
주의할 점은 데이터가 아니라 체크섬이 손상될 수도 있는데, 체크섬은 데이터에 비해 매우 작기 때문에 손상 가능성은 매우 낮다.  

#### HDFS 의 데이터 무결성 
HDFS는 모든 데이터를 쓰는 과정에서 체크섬을 계산하고, 읽는 과정에서 검증한다.  
데이터노드는 데이터와 체크섬을 저장하기 전에 수신한 데이터를 검증할 책임이 있다.  
이 같은 검증은 클라이언트로부터 수신한 데이터 또는 복제 과정에서 다른 데이터노드로부터 수신한 데이터에 대해 수행된다.  

클라이언트가 데이터노드로부터 데이터를 읽을 때 클라이언트 역시 데이터노드에 저장된 체크섬과 수신된 데이터로부터 계산된 체크섬을 검증한다.  
각 데이터노드는 체크섬 검증 로그를 영구 저장하기 때문에 각각의 블록이 검증되었던 마지막 시간을 알고 있다.  
클라이언트가 성공적으로 하나의 블록을 검증하고 데이터노드에 알리면 데이터노드는 체크섬 검증에 대한 로그를 갱신한다.  

각 데이터노드는 저장된 모든 블록을 주기적으로 검증하는 DataBlockScanner 를 백그라운드 스레드로 수행한다.  
물리먹 저장 매체에서 발생할 수도 있는 '비트 로트(bit rot)'에 의한 데이터 손실을 피하기 위한 방법이다.  

HDFS는 블록의 복제본을 저장하기 때문에 손상되지 않은 새로운 복제본 생성을 위해 정상 복제본 중 하나를 복사하는 방식으로 손상된 블록을 치료할 수 있다.  
만약 클라이언트가 블록을 읽는 과정에서 에러를 검출하는 훼손된 블록과 데이터노드에 대한 정보를 네임노드에 보고하고 에러를 발생시킨다.  
네임노드는 그 블록 복제본이 손상되었다고 표시하여 다른데서 사용하지 못하게 하고, 해당 블록을 복구한다. 
 
#### LocalFileSystem
하둡 LocalFileSystem 은 클라이언트 측 체크섬을 수행한다.  
filename 이라는 파일을 쓸 때 파일 시스템 클라이언트는 파일과 같은 위치의 디렉터리에 그 파일의 청크별 체크섬이 담긴 .filename.crc라는 숨겨진 파일을 생성한다.  

체크섬은 일반적으로 파일을 읽고 쓰는 시간에 몇 퍼센트의 오버헤드를 추가하는 정도이므로 전체 계산 성능에 미치는 영향이 미미하다.  
만일 기존 파일시스템이 체크섬 기능을 지원한다면, LocalFileSystem 의 체크섬 기능을 비활성화 할 수 있다. 


### 압축 
파일 압축은 파일 저장 공간을 줄이고, 네트워크 또는 디스크로부터 데이터 전송을 고속화할 수 있는 이점이 있다.  
이 이점은 대용량 데이터를 처리할 때 매우 중요하기 때문에 하둡에서 압축이 사용되는 방법을 주의 깊게 살펴봐야 한다.  

다음은 하둡에서 사용할 수 있는 일반적인 알고리즘이다. 

|압축포맷|도구|알고리즘|파일 확장명|분할 가능|
|---|---|---|---|---|
|DEFLATE|N/A|DEFLATE|.deflate|No|
|gzip|gzip|DEFLATE|.gz|No|
|bzip2|bzip2|bzip2|.bz2|Yes|
|LZO|lzop|LZO|.lzo|No|
|LZ4|N/A|LZ4|.lz4|No|
|Snappy|N/A|Snappy|.snappy|No|

모든 압축 알고리즘은 압축과 해제가 빨라질수록 공간이 늘어나는 희생을 감수해야 하기 때문에 공간과 시간은 트레이드오프 관계에 있다.  

#### 코덱
**코덱**은 압축-해제 알고리즘을 구현한 것이다.  
