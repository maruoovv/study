## 하둡 관리

하둡 클러스터를 원할히 운영하기 위한 절차를 알아보자.

### HDFS

#### 영속적인 데이터 구조 

하둡관리자는 HDFS 의 컴포넌트인 네임노드, 보조네임노드, 데이터노드가 데이터를 디스크에 구성하는 방식을 이해할 필요가 있다.

##### 네임노드 디렉토리 구조
```
${dfs.namenode.name.dir}/  
|- current  
	|- VERSION
	|- edits_00000000..1 - edits_00000....19
	|- edits_inprogress_000...20
	|- fsimage_000...00
	|- fsimage_000...00.md5
	|- fsimage_000...19
	|- fsimage_000...19.md5
	|- seen_txid
|- in_use.lock 
```

in_use.lock 파일은 네임노드가 저장소 디렉터리를 잠그는 데 사용하는 잠금 파일이다.  
다른 네임노드의 인스턴스가 동일한 저장소 디렉터리에서 실행되는것을 방지하는 역할을 한다.  

dfs.namenode.name.dir 은 디렉토리의 목록으로, 각 디렉터리는 동일한 내용이 복제되어 있다.  
VERSION 은 자바 속성 파일이다. 일반적인 파일의 내용은 다음과 같다.
```
namespaceID=1342387246
clusterID=CID-01b5c398-959c-4ea8-aae6-1e0d9bd8b142
cTime=0
storageType=NAME_NODE
blockpoolID=BP-526805057-127.0.0.1-1411980876842
layoutVersion=-57
```
- namespaceID : 파일시스템 네임스페이스의 유일한 식별자이다.  
- clusterID : HDFS 클러스터 전체의 유일한 식별자이다. HDFS 페더레이션을 구성할 때 중요한 역할을 한다.
- cTime : 네임노드 저장소의 생성 시간을 표시한다.
- storageType : 해당 저장소의 디렉터리가 네임노드 데이터 구조를 가진다는 것을 의미한다.
- blockpoolID : 네임노드가 관리하는 네임스페이스의 모든 파일이 들어 있는 블록 풀의 유일한 식별자다.
- layoutVersion : HDFS의 영속적인 데이터 구조의 버전을 나타낸다. 하둡 배포판의 릴리즈 버전과는 관계가 없다.  

edits, fsimage, seen_txid 같은 파일들도 있는데, 이 파일의 용도를 이해하려면 네임노드의 동작 방식을 좀 더 알아야 한다.

##### 파일시스템 이미지와 에디트 로그

파일시스템의 클라이언트가 쓰기 동작을 하면 일단 에디트 로그에 해당 내역이 기록된다.  
네임노드는 파일시스템의 메타데이터를 인메모리로 관리하는데, 에디트 로그를 먼저 변경한 후 메모리상의 데이터를 변경한다.  
클라이언트의 읽기 요청은 인메모리 데이터만 사용한다.  

에디트 로그는 디스크에서 다수의 파일로 관리된다.  
각 파일을 **세그먼트**라고 하며 edits_txid 로 구성된다.  
한번에 하나의 파일에만 쓰며, 쓰기 동작이 끝날 때마다 에디트 로그를 플러시하여 동기화 시킨다.  
네임노드는 여러 개의 디렉토리에 에디트 로그를 기록할 수 있기 때문에 변경 내역을 모든 에디트 로그 복제본 파일에 플러시 하고 동기화 한 후 성공했다는 것을 알려주어야 한다.  

fsimage 파일은 파일시스템 메타데이터의 완전하고 영속적인 체크포인트다.
파일시스템에 존재하는 모든 디렉터리, 파일의 아이노드 정보를 직렬화 한 파일이다.   
블록이 실제 저장된 데이터노드에 대한 정보는 fsimage 에는 저장되지 않고, 메모리에서 따로 관리한다.   
파일시스템의 쓰기 동작이 있을 때마다 fsimage 파일을 변경하지는 않는다. (fsimage 파일이 GB 단위로 커지면 성능이 매우 느려짐)

에디트 로그 파일은 무한정 커질 수 있다.  
이는 네임노드가 구동 중일 때는 특별한 영향을 주지 않지만, 
네임노드가 재시작될 경우 매우 큰 에디트 로그의 변경 내역을 모두 적용하기 위해선 많은 시간이 소요되고, 이 작업 동안 파일시스템을 사용하지 못하는 상황에 처할 수 있다.

이 문제의 해결책은 보조 네임노드를 운영하는 것이다. 보조 네임노드는 주 네임노드의 메모리에 있는 파일시스템 메타데이터의 체크포인트를 만드는 것이다. (체크포인팅 작업)   
 
1. 보조 네임노드는 주 네임노드에서 사용 중인 edits 파일을 순환할 것을 요청한다. 이제부터 발생하는 로그는 새로운 파일에 저장된다. 주 네임노드는 모든 디렉토리의 seen_txid 파일을 변경한다.  
2. 보조 네임노드는 주 네임노드에 있는 최신 fsiamge, edits 를 가져온다.
3. 보조 네임노드는 fsimage 파일을 메모리에 올리고 edits 파일의 각 변경 내역을 적용한다. 그리고 병합된 새로운 fsimage 파일을 생성한다.  
4. 보조 네임노드는 새로운 fsimage 파일을 주 네임노드에 전송하고, 주 네임노드는 받은 파일을 .ckpt 확장자로 임시 저장한다.
5. 임시 저장한 fsimage 파일의 이름을 변경하여 사용 가능하게 만든다.

보조 네임노드는 체크포인팅 작업시 fsimage를 메모리에 올리므로, 주 네임노드와 비슷한 메모리 용량을 가져야 한다.  
체크포인팅은 일정 시간(dfs.namenode.checkpoint.check.period) 마다 에디트 로그를 확인하여 마지막 체크포인트 이후 기록된 변경 내역의 갯수가 일정횟수(dfs.namnode.checkpoint.txns)를 넘으면 새로운 체크포인트를 생성한다.
보조 네임노드 디렉토리 구조는 주 네임노드와 동일하다.  

##### 데이터노드 디렉터리 구조 
```
${dfs.datanode.data.dir}/
|- current
	|- BP-526805057-127.0.0.1-1411980876842
		|- current
			|- VERSION
			|- finalized
				|- blk_1073741825
				|- blk_1073741825_1001.meta
				|- blk_1073741826
				|- blk_1073741826_1002.meta
			|- rbw
	|- VERSION
|- in_use.lock
```

HDFS 의 각 블록은 blk_ 으로 시작되는 파일에 저장된다.  
각 블록은 blk_ 외에도 .meta 로 끝나는 메타데이터 파일을 가진다. (버전, 타입 정보를 가진헤더 + 블록 구간별 체크섬)  
각 블록은 블록풀에 속해 있고, 각 블록 풀은 블록Id로 된 디렉터리를 가진다.  
하나의 디렉터리에 저장된 블록의 수가 지정된 개수를 넘어서면 데이터노드는 새로운 서브 디렉터리를 생성하여 저장한다.  

#### 안전 모드
네임노드를 시작할 때 처음 수행되는 일은 이미지파일을 메모리상에 로드하고 에디트 로그의 변경 내역을 반영하는 것이다.  
(보조 네임노드에 맡기지 않고 주 네임노드가 체크포인팅 작업을 수행한다.)    
이 과정이 수행되는 동안 네임노드는 **안전모드** 로 동작하는데, 이 때 클라이언트는 읽기 동작만 할 수 있다.  
안전모드에서 네임노드는 데이터노드로부터 자신이 가지고 있는 블록 목록을 받고, 이 정보를 등록한다.  
**최소복제조건**을 만족 한 후 30초가 지나면 안전모드가 해제된다.  

#### 감사 로깅
HDFS는 모든 파일시스템의 접근 요청을 기록할 수 있다.  
hadoop-env.sh 에 아래 내용을 추가하면 로깅을 활성화 할 수 있다.
```
export HDFS_AUDIT_LOGGER="INFO, RFAAUDIT"
```

#### 도구 

##### 밸런서 
시간이 흐를수록 데이터노드 사이의 블록의 분포는 불균형 상태가 될 수 있다.  
이는 맵리듀스의 지역성이 영향을 받아 자주 사용되는 데이터 노드에 큰 부하를 줄 수 있다.  
밸런서 프로그램은 사용률이 높은 데이터노드의 블록을 사용률이 낮은 데이터노드로 옮기는 하둡 데몬이다.  
밸런서는 클러스터가 균형 상태가 될 때 까지 블록을 이동시킨다.  
클러스터에 과도한 부하를 주지 않고 클러스터를 사용하는 클라이언트에 방해가 되지 않기 위해 백그라운드로 실행된다.  


### 모니터링 
모니터링의 목적은 클러스터가 기대하는 수준의 서비스를 제공하지 못하는 시점을 감지하는 것이다.  
주 네임노드, 보조 네임노드, 리소스 매니저와 같은 마스터 데몬이 가장 중요한 모니터링 대상이다. 

#### 로깅 

##### 로그 수준 설정 
하둡 데몬은 log4j 로그파일의 로그 수준을 변경할 수 있는 웹 페이지를 제공한다.
http://resource-manager-host:8088/logLevel

##### 스택 트레이스 얻기 
하둡 데몬은 모든 스레드에 대해 덤프를 생성할 수 있는 웹페이지를 제공한다. 
http://resource-manager-host:8088/stacks

#### 메트릭과 JMX
하둡 데몬은 메트릭 으로 알려진 이벤트와 측정치에 대한 정보를 수집한다.  
예를 들면 데이터노드는 기록된 바이트 수, 복제된 블록 수, 읽기 요청 수 등..  

메트릭은 dfs, mapred, yarn, rpc 등 여러 콘텍스트에 속해 있고, 하둡 데몬은 여러 콘텍스트의 메트릭을 수집한다.  
하둡 메트릭은 JMX로 게재되기 떄문에 JConsole 과 같은 표준 JMX 도구를 사용하여 메트릭을 볼 수 있다.  
하둡 데몬의 /jmx 웹페이지에 접속하면 해당 데몬이 수집한 JMX 메트릭을 볼 수 있다.  

### 유지보수

#### 메타데이터 백업
네임노드의 메타데이터가 손실되면 전체 파일 시스템을 사용할 수 없게 된다. 따라서 이 팡리을 백업하는 것은 중요하다.  
dfsadmin 명령어를 사용하여 네임노드의 최신 fsimage 를 백업한다. 
```
hdfs dfsadmin -fetchImage fsimage.backup
```

#### 데이터 백업
HDFS는 데이터를 안전하게 저장하도록 설계되었지만 데이터 손실이 발생할 가능성이 있다. (HDFS에 데이터 복제 기능이 있다고 하지만 이것이 백업을 대체할 수는 없다.)    
하둡의 데이터 크기는 엄청나기 때문에 모든 데이터를 백업하는것은 힘들고, 데이터의 우선순위를 정하여 백업하는 것이 좋다.
HDFS의 사용자 디렉토리 별로 정책을 수립하는 것이 일반적이다.  

#### 노드의 추가와 퇴역
하둡 클러스터 관리자는 노드를 추가하거나 제거해야할 때도 있다.  

##### 노드 추가 
hdfs-site.xml 파일에 네임노드, yarn-site.xml 파일에 리소스 매니저를 지정하여 데몬을 시작하면 새로운 노드를 간단히 추가할 수 있다.  
하지만 추가를 허용하는 노드 목록을 따로 만들어두는 것이 제일 좋다.  

네임노드에 연결이 허용된 데이터노드는 dfs.hosts 속성으로 지정된 파일에 명시된다.  
리소스 매니저에 접속하는 노드 매니저는 yarn.resourcemanager.nodes.include-path 속성에 지정된 파일에 명시된다.  
클러스터의 노드는 데이터노드와 노드매니저를 모두 실행하므로 대개 하나의 **include** 파일을 두고 각 설정에서 이 파일을 참조하는 것이 좋다.    
클러스터에 새로운 노드를 추가하는 절차는 다음과 같다.  

1. include 파일에 새로운 노드의 네트워크 주소를 추가
2. 새로 허가된 데이터노드 집합을 네임노드에 반영 (hdfs dfsadmin -refreshNodes)
3. 새로 허가된 노드 매니저 집합을 리소스 매니저에 반영 (yarn rmadmin -refreshNodes)
4. 새로 추가된 노드를 slaves 파일에 반영하여 하둡 제어 스크립트가 다룰 수 있도록 한다.
5. 새로운 데이터노드와 노드 매니저를 시작한다. 

##### 노드 퇴역 
노드를 하둡 클러스터에서 퇴역시키는 절차는 exclude 파일로 제어하며 HDFS 는 dfs.hosts.exclude, YARN은 yarn.resourcemaanger.nodes.exclude-path 속성에 파일을 명시한다.  
exclude 파일에는 하둡 클러스터에 접속이 허가되지 않은 노드를 열거한다.  

노드 매니저는 include 파일에는 있고 exclude 파일에 없을 경우에만 리소스 매니저에 접속할 수 있다.  
include 파일을 지정하지 않거나 비어있으면 모든 노드가 include 파일 리스트에 있다고 간주한다. 

HDFS의 경우엔 데이터노드가 include와 exclude 파일의 목록에 모두 있으면 접속할 수는 있지만 곧 해제된다.  

하둡 클러스터에서 노드를 퇴역시키는 절차는 다음과 같다.

1. exclude 파일에 해제할 노드의 네트워크 주소를 추가한다. 
2. 새롭게 허가된 데이터노드 집합으로 네임노드를 갱신한다 (hdfs dfsadmin -refreshNodes)
3. 새롭게 허가된 노드 매니저 집합으로 리소스 매니저를 갱신한다 (yarn rmadmin -refreshNodes)
4. 웹 UI에 접속하여 퇴역시킬 데이터노드의 관리 상태가 Decommission in Progress(해제 진행중) 으로 변했는지 확인한다. 
대상 데이터노드는 자신의 블록을 클러스터의 다른 데이터노드로 복제하는 작업을 시작한다.
5. 모든 데이터노드 관리 상태가 Decommissioned 가 되면 모든 블록의 복제가 완료된 것이므로 퇴역시킨 노드를 중단시킨다.
6. include 파일에서 해당 노드를 삭제하고 2,3 번의 명령어를 수행한다.
 
